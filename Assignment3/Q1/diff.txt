diff --git a/Makefile b/Makefile
index 51540b291..19efd4be1 100644
--- a/Makefile
+++ b/Makefile
@@ -1094,7 +1094,7 @@ export MODORDER := $(extmod-prefix)modules.order
 export MODULES_NSDEPS := $(extmod-prefix)modules.nsdeps
 
 ifeq ($(KBUILD_EXTMOD),)
-core-y		+= kernel/ certs/ mm/ fs/ ipc/ security/ crypto/ block/
+core-y		+= kernel/ certs/ mm/ fs/ ipc/ security/ crypto/ block/ info/
 
 vmlinux-dirs	:= $(patsubst %/,%,$(filter %/, \
 		     $(core-y) $(core-m) $(drivers-y) $(drivers-m) \
diff --git a/arch/x86/entry/syscalls/syscall_64.tbl b/arch/x86/entry/syscalls/syscall_64.tbl
index f30d6ae9a..4d0f913b1 100644
--- a/arch/x86/entry/syscalls/syscall_64.tbl
+++ b/arch/x86/entry/syscalls/syscall_64.tbl
@@ -361,6 +361,7 @@
 437	common	openat2			sys_openat2
 438	common	pidfd_getfd		sys_pidfd_getfd
 439	common	faccessat2		sys_faccessat2
+440 common	rtnice			sys_rtnice
 
 #
 # x32-specific system call numbers start at 512 to avoid cache impact
diff --git a/include/linux/sched.h b/include/linux/sched.h
index afe01e232..91d866c8d 100644
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@ -461,6 +461,9 @@ struct sched_entity {
 
 	u64				nr_migrations;
 
+	/* Adding a new variable for soft time requirements */
+	u64				softruntime;
+
 	struct sched_statistics		statistics;
 
 #ifdef CONFIG_FAIR_GROUP_SCHED
@@ -2049,3 +2052,4 @@ int sched_trace_rq_nr_running(struct rq *rq);
 const struct cpumask *sched_trace_rd_span(struct root_domain *rd);
 
 #endif
+
diff --git a/include/linux/syscalls.h b/include/linux/syscalls.h
index 75ac7f8ae..7750b9095 100644
--- a/include/linux/syscalls.h
+++ b/include/linux/syscalls.h
@@ -1345,4 +1345,5 @@ int __sys_getsockopt(int fd, int level, int optname, char __user *optval,
 		int __user *optlen);
 int __sys_setsockopt(int fd, int level, int optname, char __user *optval,
 		int optlen);
+asmlinkage long sys_rtnice(int pid, s64 softruntime);
 #endif
diff --git a/info/Makefile b/info/Makefile
new file mode 100644
index 000000000..ec89d70b3
--- /dev/null
+++ b/info/Makefile
@@ -0,0 +1 @@
+obj-y:=rtnice.o
diff --git a/info/rtnice.c b/info/rtnice.c
new file mode 100644
index 000000000..bbfa5ff58
--- /dev/null
+++ b/info/rtnice.c
@@ -0,0 +1,28 @@
+#include<linux/kernel.h>
+#include<linux/init.h>
+#include<linux/sched.h>
+#include<linux/syscalls.h>
+
+#include <linux/errno.h>
+
+
+SYSCALL_DEFINE2(rtnice, int, pid, s64, softruntime) {
+  struct task_struct *proces = NULL, *temp = NULL;
+
+  if(pid <= 0 || softruntime <= 0)
+    return -EINVAL;
+
+  for_each_process(temp) {
+    if((long)task_pid_nr(temp) == pid) {
+      proces = temp;
+      break;
+    }
+  }
+
+  if(proces == NULL)
+    return -EINVAL;
+
+  proces->se.softruntime = softruntime;
+  printk("softruntime value succesfully changed for pid: %d, value: %lld\n", pid, softruntime);
+  return 0;
+}
diff --git a/kernel/sched/core.c b/kernel/sched/core.c
index 2d95dc3f4..4c27b1497 100644
--- a/kernel/sched/core.c
+++ b/kernel/sched/core.c
@@ -3070,6 +3070,10 @@ static void __sched_fork(unsigned long clone_flags, struct task_struct *p)
 	p->se.prev_sum_exec_runtime	= 0;
 	p->se.nr_migrations		= 0;
 	p->se.vruntime			= 0;
+
+	/* Initializing softruntime requirement with 0 */
+	p->se.softruntime		= 0;
+	
 	INIT_LIST_HEAD(&p->se.group_node);
 
 #ifdef CONFIG_FAIR_GROUP_SCHED
@@ -8482,3 +8486,4 @@ void call_trace_sched_update_nr_running(struct rq *rq, int count)
 {
         trace_sched_update_nr_running_tp(rq, count);
 }
+
diff --git a/kernel/sched/fair.c b/kernel/sched/fair.c
index 1a68a0536..62430f5c1 100644
--- a/kernel/sched/fair.c
+++ b/kernel/sched/fair.c
@@ -534,6 +534,22 @@ static inline u64 min_vruntime(u64 min_vruntime, u64 vruntime)
 static inline int entity_before(struct sched_entity *a,
 				struct sched_entity *b)
 {
+
+	/*
+	 * If softruntime diff is non zero, decide on the basis of softruntime
+	 * else leave upto old kernel to decide on the basis of vruntime
+	 */
+	s64 softruntimediff = (a->softruntime - b->softruntime);
+	if(softruntimediff != 0) {
+		/* When either of them is zero, choose the other one */
+		if(a->softruntime == 0)
+			return 0;
+		else if(b->softruntime == 0)
+			return 1;
+
+		return softruntimediff < 0;
+	}
+
 	return (s64)(a->vruntime - b->vruntime) < 0;
 }
 
@@ -871,6 +887,15 @@ static void update_curr(struct cfs_rq *cfs_rq)
 		account_group_exec_runtime(curtask, delta_exec);
 	}
 
+	if(curr->softruntime > 0) {
+		u64 diff = curr->softruntime - delta_exec;
+
+		if(diff < 0)
+			curr->softruntime = 0;
+		else
+			curr->softruntime = diff;
+	}
+
 	account_cfs_rq_runtime(cfs_rq, delta_exec);
 }
 
@@ -6844,6 +6869,25 @@ wakeup_preempt_entity(struct sched_entity *curr, struct sched_entity *se)
 {
 	s64 gran, vdiff = curr->vruntime - se->vruntime;
 
+	/*
+	 * This function decides if sched_entity se should preempt curr
+	 * We first check if se has some softruntime requirements
+	 *   -> If yes, prempt on the basis of softruntime
+	 *   -> If no, then decide according to vruntime
+	 */
+	
+	/* Caclulate the difference between softruntime of two tasks */
+	s64 softruntimediff = curr->softruntime - se->softruntime;
+
+	if(softruntimediff != 0) {
+		if(curr->softruntime == 0)
+			return 0;
+		if(se->softruntime == 0)
+			return -1;
+
+		return softruntimediff < 0;
+	}
+
 	if (vdiff <= 0)
 		return -1;
 
@@ -11317,3 +11361,4 @@ int sched_trace_rq_nr_running(struct rq *rq)
         return rq ? rq->nr_running : -1;
 }
 EXPORT_SYMBOL_GPL(sched_trace_rq_nr_running);
+
